version: '3.8'

services:
  redis:
    image: redis:7.2-alpine
    container_name: scraper_redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    environment:
      - TZ=UTC
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - scraper_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  selenium:
    image: seleniarm/standalone-chromium:latest
    container_name: scraper_selenium
    shm_size: 2g
    ports:
      - "${SELENIUM_PORT:-4444}:4444"
      - "${SELENIUM_VNC_PORT:-5900}:5900"
    environment:
      - TZ=UTC
      - SE_NODE_MAX_SESSIONS=4
      - SE_NODE_OVERRIDE_MAX_SESSIONS=true
      - SE_SESSION_REQUEST_TIMEOUT=300
      - SE_START_XVFB=true
    volumes:
      - /dev/shm:/dev/shm
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - scraper_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4444/wd/hub/status"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

networks:
  scraper_net:
    name: scraper_network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16

volumes:
  redis_data:
    name: scraper_redis_data 